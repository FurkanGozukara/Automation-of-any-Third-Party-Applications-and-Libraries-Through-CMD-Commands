Hello dear students, welcome to the lecture tonight of software engineering course.
So today's topic is...
Dependability and security specification.
Okay, the topics we are going to cover today are...
Risk-driven specification.
Safety specification.
Security specification.
Software reliability specification.
Okay, so let's start with...
Dependability requirements.
Functional requirements to define error checking and recovery facilities and protection against system failures.
Non-functional requirements defining the required reliability and availability of the system,
excluding requirements that define states and conditions that must not arise.
Okay, some of the students were confused with non-functional requirements.
You see, that is defining the required reliability and availability of the system,
and which will be non-functional requirements.
Okay, let's continue.
Risk-driven specification.
Critical system specification should be risk-driven.
This approach has been widely used in safety and security critical systems.
The aim of the specification process should be to understand the risks, safety, security, et cetera, faced by the system and to define requirements that reduce these risks.
Stages of risk-based analysis.
Okay, first risk identification.
Identify potential risks that may arise.
Risk analysis and classification assess the seriousness of each risk.
Risk decomposition.
Decommal decomposed risks.
To discover the potential root causes.
Risk reduction assessment.
Define how each risk must be taken into an eliminated or reduced
when the system is designed.
Okay, so the risk-driven specification is shown like this.
And one moment I will fix this.
Okay, so risk-driven specification.
You see there is risk identification and risk description.
Then there is risk analysis and risk assessment.
Risk decomposition root cause of analysis.
To say it correctly root cause analysis.
Okay, risk reduction and dependability requirements.
Faced risk analysis.
Preliminary risk analysis.
Identifies risks from the system's environment.
Aim is to develop an initial set of system security and dependability requirements.
Life cycle risk analysis.
Identifies risks that emerge during design and development e.g. risks that are associated with the technologies used for system construction.
Requirements are extended to protect against these risks.
Operational risk analysis.
Risk associated with the system user interface and operator errors.
Further protection requirements may be added to cope with these.
Safety specification.
Okay.
Goal is to identify protection requirements that ensure that system failures do not cause injury or death
or environmental damage.
Risk identification equals hazard identification.
Risk analysis equals hazard assessment.
Risk decomposition equals hazard analysis.
Risk reduction equals safety requirements specification.
Okay, so this is a much more explanative.
When you think as an hazard.
Risk identification equals hazard identification.
Risk analysis equals hazard assessment.
Risk decomposition equals hazard analysis.
Risk reduction equals safety requirements specification.
Okay.
Hazard identification.
Identify the hazards that may threaten the system.
Hazard identification may be based on different types of hazard.
Physical hazards, electrical hazards, biological hazards, service failure hazards, etc.
Insulin pump risks.
You see, they develop an insulin pump.
They also analyze assess the risks that comes with the system.
It is extremely important.
Insulin overdose, service failure.
Insulin underdose, service failure.
Power failure due to exhausted battery electrical.
Electrical interference with other medical equipment electrical.
Poor sensor and actuator contact physical.
Parts of machine break off in body physical.
Infection caused by introduction of machine biological.
Allurgic reaction to materials or insulin biological.
You see, they are separated by the related categories such as service failure, electrical, physical biology.
Hazard assessment.
The process is concerned with understanding the likelihood that a risk will arise
and the potential consequences if an accident or incident should occur.
Risks may be categorized as.
Intolerable must never arise or result in an accident.
As low as reasonably practical ALARP must minimize the possibility of risk given cost and schedule constraints.
Acceptable, the consequences of the risk are acceptable and no extra cost should be incurred
to reduce hazard probability.
The risk triangle is like this.
You see ALARP region, which is as low as reasonably practical.
Risk tolerated only if risk deduction is in practical or excessive the expansive desire.
And there is acceptable region, this area, negligible risk and at the very top or the bottom of the reverse.
The triangle, unacceptable region, this cannot be tolerated.
Such as it may lead to that.
When you overdose the patient, it may result in death.
Therefore, it is unacceptable.
Social acceptability of risk.
The acceptability of a risk is determined by human, social and political considerations.
In most societies, the boundaries between the regions are pushed upwards with time i.e. society is less willing to accept risk.
For example, the costs of cleaning up pollution may be less than the costs of preventing it but this may not be socially acceptable.
Risk assessment is subjective.
Risks are identified as probable, unlikely, etc.
This depends on who is making the assessment.
So the use of risk assessment is subjective, it is not very much objective.
However, you may follow some approaches to have somewhat balanced or more objective this assessment.
Estimate the risk probability and the risk severity.
It is not normally possible to do this precisely so relative values are used such as unlikely, rare, very high, etc.
etc. the aim must be to exclude risks that are likely to arise or that have high severity.
Risk classification for the insulin pump.
Okay, the first column is identified as second one is hazard probability, third is accident severity, fourth is estimated risk.
One, insulin overdose computation medium high high intolerable.
Two, insulin underdose computation.
So you see underdose computation doesn't necessarily harm or let's say, doesn't necessarily induce acute harm.
Therefore, the accident severity is low, therefore it is acceptable.
Payed of hard laboration system, it may have medium chance and accident severity is medium.
Therefore, it is estimated risk is low, however, this time it is not acceptable, but ARP.
Because the accident severity is also not low, it is accident severity is medium, not low, therefore it is a bit more unacceptable than acceptable.
Power failure hazard probability is high, it may happen.
Commonly accident severity is low, therefore the estimated risk is low, acceptable.
Machine incorrectly fitted hazard probability high, accident severity high, therefore estimated risk is high, therefore it is intolerable.
The machine breaks in patient hazard probability low, so it may happen rarely, accident severity is high, therefore estimated risk is medium, therefore it is ARP.
Machine causes infection hazard probability medium, accident severity medium, estimated risk is medium.
Electrical inference, low high, medium, energy creation, low, low, acceptable.
So, I will add this to your course.
I mean your semester project requirement.
As a project it is okay.
So, we have also added some more independent lecture if you remember.
So, let's call it as,
okay.
All right, let's continue.
Hazard analysis
Concerned with discovering the root causes of risks in a particular system, techniques have been mostly derived from safety critical systems and can be.
Inductive, bottom-up techniques.
Start with a proposed system failure and assess the hazards that could arise from that failure, deductive, top-down techniques.
Start with a hazard and deduce what the causes of this could be.
Fault tree analysis
A deductive top-down technique, put the risk or hazard at the root of the tree and identify the system states that could lead to that hazard.
Where appropriate lengthies with and or conditions.
A goal should be to minimize the number of single causes of system failure.
An example of a software fault tree.
So, it starts from top and goes to the bottom in here.
I think incorrect insulin dose administered.
So, the error here is incorrect insulin dose administration and then it starts branching and calculating how might it happen.
So, it may happen due to one of these three reasons you see there or incorrect sugar level measured.
Correct dose delivered at the wrong time delivery system failure.
So, each of these error may cause incorrect insulin dose administration.
So, incorrect sugar level measured can be caused by two errors which are sensor failure or sugar computation error.
Then the sugar computation error may be caused by two different errors.
Which are algorithm error or arithmetic error.
The correct dose delivered at the wrong time may be happening.
Maybe caused by the timer failure.
The delivery system failure may be caused by two different errors.
First one is insulin computation is incorrect or prompt thickness incorrect.
Some computation incorrect may be caused by two different errors which are algorithm error and arithmetic error.
Next add this to your project.
Page.
Fault tree analysis.
Three possible conditions that can lead to delivery of incorrect dose of insulin.
Incorrect measurement of blood sugar level failure of delivery system dose delivered at wrong time.
By analysis of the fault tree, root causes of these hazards related to software are.
Algorithm error or arithmetic error.
Risk reduction.
The aim of this process is to identify dependability requirements that specify how the risk should be managed and ensure that accidents incidents do not arise.
Risk reduction strategies risk avoidance, risk detection and removal, damage limitation.
You see there are three strategies that we can apply risk avoidance which is best.
We avoid risk if possible risk detection and removal.
This is about taking the risk and removing it before the actual damage is done.
And the last one is the risk happens but we try to limit it damage.
Strategy use.
Normally in critical systems, a mix of risk reduction strategies are used.
In a chemical plant control system, the system will include sensors to detect and correct excess pressure in the reactor.
However, it will also include an independent protection system that opens a relief valve if dangerously high pressure is detected.
So you see it is mix of strategies.
The first strategy is the system will include sensors to detect and correct excess pressure in the reactor.
Which is the detection and removal.
And the third one is damage limitation.
However, it will also include an independent protection system that opens a relief valve if dangerously high pressure is detected.
Incel and pump, software risks.
A arithmetic error a computation causes the value of a variable to overflow or underflow.
Maybe include an exception handler for each type of arithmetic error.
Algorithmic error compare dose to be delivered with previous dose or safe maximum doses.
Reduce dose if too high.
Examples of safety requirements.
Okay, one more time.
State Route 1, the system shall not deliver a single dose of insulin that is greater than a specified maximum dose for a system user.
State Route 2, the system shall not deliver a daily cumulative dose of insulin that is greater than a specified maximum daily dose for a system user.
State Route 3, the system shall include a hardware diagnostic facility that shall be executed at least four times per hour.
State Route 4, the system shall include an exception handler for all of the exceptions that are identified in Table 3.
State Route 5, the audible alarm shall be sounded when any hardware or software anomaly is discovered in a diagnostic message as defined in Table 4 shall be displayed.
State Route 6, in the event of an alarm, insulin delivery shall be suspended until the user has reset the system and cleared the alarm.
UsVDs are the safe requirements that are defined to prevent incidents or harm or damage. So that's it. Something like to use to your project as well.
Prepare an example solve.
Prepare an example of safety requirements such as for your system.
So the key points of the first part is like here, let's read it.
Risk analysis is an important activity in the specification of security and dependability requirements.
It involves identifying risks that can result in accidents or incidents. A hazard driven approach may be used to understand the safety requirements for a system.
You identify potential hazards and decompose these using methods such as fault tree analysis to discover their root causes.
Safety requirements should be included to ensure that hazards and accidents do not arise or if this is impossible to limit the damage caused by system failure.
So your system that you are going to develop for this course may not have health hazard or such harmful hazard. However, you can still define risk requirements.
Those risks may not be very important, but there will be still some risks that can bother the users that can affect the user and you should define them.
So any system for every system can be defined.
System reliability specification
Reliability is a measurable system attribute so non-functional reliability requirements may be specified quantitatively.
These define the number of failures that are acceptable during normal use of the system or the time in which the system must be available.
Functional reliability requirements define system and software functions that avoid, detect or tolerate faults in the software and so ensure that these faults do not lead to system failure.
Software reliability requirements may also be included to cope with hardware failure or operator error.
Reliability specification process risk identification.
Identified types of system failure that may lead to economic losses.
So let's say you are developing a commerce website. This can be defined. You are developing a suitable management system. This can be defined for any system. You are developing a game. This can be defined.
Risk analysis.
Estimate the costs and consequences of the different types of software failure.
Risk decomposition.
Identify the root causes of system failure.
Generate reliability specifications including quantitative requirements defining the acceptable levels of failure.
Okay, types of system failure. So that is system failure types.
Failure type on description.
Lof of service. Okay.
The system is unavailable and cannot deliver its services to users. You may separate this into loss of critical services and loss of non-critical services,
or the consequences of a failure in non-critical services or less than the consequences of critical service failure.
The system does not deliver a service correctly to users. Again, this may be specified in terms of minor and major errors or errors in the delivery of critical and non-critical services.
And system data system or data corruption.
The failure of the system causes damage to the system itself or its data.
This will usually but not necessarily be in conjunction with other types of failures.
All right, and then as reliable metrics.
Reliability metrics are units of measurement of system reliability.
System reliability is measured by counting the number of operational failures and where appropriate,
relating these to the demands made on the system and the time that the system has been operational.
A long-term measurement program is required to assess the reliability of critical systems.
Okay, what metrics are you using, probability of failure on demand, rate of occurrence of failures mean time to failure, available to you.
Okay.
Probability of failure on demand, POFOD.
This is the probability that the system will fail when a service request is made.
Useful when demands for service are intermittent and relatively infrequent.
Appropriate for protection systems where services are demanded occasionally and where there are serious consequences if the service is not delivered.
Relevant for many safety critical systems with exception management components.
Okay, for example, emergency shutdown system in a chemical plot.
You see, this is how it is important.
This may never be used, therefore it is very infrequently used.
However, when it is necessary, failure of this system would cause catastrophic damage.
Okay, so you see how it is important for a probability of failure on demand.
Rate of fault occurrence, ROCOF.
Reflects the rate of occurrence of failure in the system, ROCOF of 0.002 means two failures are likely in each 1,000 operational time units EG, two failures per 1,000 hours of operation.
Relevant for systems where the system has to process a large number of similar requests in a short time credit card processing system, airline booking system,
reciprocal of ROCOF is mean time to failure, MTTF, relevant for systems with long transactions, i.e. where system processing takes a long time EG CAD systems.
MTTF should be longer than expected transaction length.
Okay, available at you.
Measure of the fraction of the time that the system is available for use.
Takes repair and restart time into account availability of 0.998 means software is available for 998 out of 1,000 time units.
Relevant for non-stop continuously running systems telephone switching systems railway signaling systems.
Available to specifications so that are available to you see 0.9, 0.99, 0.99, 0.99, so the explanation of 0.9.
The system is available for 90% of the time.
This means that in a 24 hour period 1,440 minutes the system will be unavailable for 144 minutes.
In a 24 hour period the system is unavailable for 14.4 minutes.
The system is unavailable for 84 seconds in a 24 hour period.
Roughly 1 minute per week.
Failure consequences
When specifying reliability it is not just the number of system failures that matter but the consequences of these failures.
Failures that have serious consequences are clearly more damaging than those where repair and recovery is straightforward.
In some cases therefore different reliability specifications for different types of failure may be defined.
Overspecification of reliability
Overspecification of reliability is a situation where a high level of reliability is specified but it is not cost effective to achieve this.
In many cases it is cheaper to accept and deal with failures rather than avoid them occurring.
To avoid overspecification specify reliability requirements for different types of failure.
Miner failures may be acceptable. Specify requirements for different services separately.
Crickle services should have the highest reliability requirements.
Decide whether or not high reliability is really required or if dependability goals can be achieved in some other way.
We need to balance between the reliability and cost of the reliability.
Therefore in many cases it is cheaper to accept and deal with failures rather than avoid them occurring.
If the occurring of event is 1 in a million it may be not practical or cost effective to avoid it.
It may be just easier to accept it and when it happens pay the costs.
Steps to a reliability specification.
For each subsystem analyze the consequences of possible system failures.
From the system failure analysis partition failures into appropriate classes.
For each failure class identified set out the reliability using an appropriate metric.
Different metrics may be used for different reliability requirements.
Identify functional reliability requirements to reduce the chances of critical failures.
Insulin pump specification.
Probability of failure P-O-F-O-D is the most appropriate metric.
Transient failures that can be repaired by user actions such as recalibration of the machine.
A relatively low value of P-O-F-O-D is acceptable, say 0.002, one failure may occur in every 500 demands.
Permanent failures require the software to be reinstalled by the manufacturer.
This should occur no more than once per year. P-O-F-O-D for this situation should be less than 0.002.
Functional reliability requirements.
Checking requirements that identify checks to ensure that incorrect data is detected before it leads to a failure.
Recovery requirements that are geared to help the system recover after a failure has occurred.
Redundancy requirements that specify redundant features of the system to be included.
Process requirements for reliability which specify the development process to be used may also be included.
Examples of functional reliability requirements for MHCPMS.
R-R-1, a predefined range for all operator inputs shall be defined and the system shall check that all operator inputs fall within this predefined range.
Checking R-R-2 copies of the patient database shall be maintained on two separate servers that are not housed in the same building.
Recovery, redundancy, R-R-3, and version programming shall be used to implement the breaking control system.
Redundancy, R-R-4, the system must be implemented in a safe subset of ADA and checked using static analysis. Process.
All night.
Security specification
Security specification has something in common with safety requirements specification in both cases your concern is to avoid something bad happening.
Four major differences.
Safety problems are accidental, the software is not operating in a hostile environment.
In security, you must assume that attackers have knowledge of system weaknesses.
When safety failures occur, you can look for the root cause or weakness that led to the failure.
When failure results from a deliberate attack, the attacker may conceal the cause of the failure.
Shudding down a system can avoid a safety-related failure.
Causing a shut down may be the aim of an attack.
Safety-related events are not generated from an intelligent adversary, and attacker can probe defenses over time to discover weaknesses.
Okay, type of security requirements. Let's see the types.
Identification requirements, authentication requirements, authorization requirements, immunity requirements, integrity requirements, intrusion detection requirements,
non-reputiation requirements, privacy requirements, security auditing requirements, system maintenance security requirements.
The preliminary risk assessment process for security requirements.
Start with asset identification. First, you need to know your assets, then you need to asset value assessment, threat identification, threat identification,
then from threat identification, attack assessment, and from attack assessment, you need to control identification,
then you need to make physical assessment of that control identification of that control, then from attack assessment, you need to make security requirement,
definition, and you need to consider physical assessment as well, then from asset value assessment, asset value assessment,
you need to calculate exposure assessment, and based on exposure assessment, attack assessment, and physical assessment, you need to define security requirement, definition, okay.
Security risk assessment.
It starts with asset identification.
Identify the key system assets or services that have to be protected, asset value assessment, estimate the value of the identified assets, exposure assessment,
assess the potential losses associated with each asset, threat identification,
identify the most probable threats to the system assets, security risk assessment, attack assessment,
decompose threats into possible attacks on the system and the ways that these may occur, control identification,
propose the controls that may be put in place to protect an asset, feasibility assessment, assess the technical feasibility and cost of the controls,
security requirements definition, defined system security requirements, these can be infrastructure or application system requirements,
asset analysis in a preliminary risk assessment report for the MHCPMS.
Okay, so the asset, for example, the information system, it's an asset or service, the value is,
high required to support all clinical consultations, potentially safety critical.
High financial loss is clinics may have to be canceled, costs of restoring system, possible patient harm if treatment cannot be prescribed.
Okay, an individual patient's records.
Okay, this is an asset.
High required to support all clinical consultations, potentially safety critical.
Okay, the exposure.
High financial loss is clinics may have to be canceled, costs of restoring system,
possible patient harm if treatment cannot be prescribed.
Okay, an individual patient's records.
Each individual patient's record is an also is also an asset.
Yeah, you see high profile patients may cause a lot of trouble than some random patients.
Okay, the exposure will be low of direct losses, but possible loss of reputation.
If certain if that patient is a high profile patient.
Threat and control analysis in a preliminary risk assessment report.
Unauthorized user gains access as system manager and makes system unavailable low only allow system management from specific locations that are physically secure.
Low cost of implementation, but care must be taken with key distribution and to ensure that keys are available in the event of an emergency.
Okay, so the threat is this, the probability is low, the control for the threat and the feasibility of the control.
You see not only control, but also the feasibility of the control is important.
For controlling only allow system management from specific locations that are physically secure. Okay, this is making sense.
However, if it is it feasible, low cost of implementation, but care must be taken with key distribution and to ensure that keys are available in the event of an emergency.
Okay, the threat, unauthorized user gains access as system user and access is confidential information. The probability is high because people may be using weak passports or.
One of your employees password may be weak or such require all users to authenticate themselves using biometric mechanism, block all changes to patient information to track system usage.
Basically feasible but high cost solution possible to use the resistance, this is simple and transparent to implement and also support recovery. You see the first control is very hard to implement, it is not much feasible.
We cannot get biometric from patients, however, the second one, logging is extremely simple and easy, therefore it should be implemented.
I think we can add this to your project as well.
The page is set and control as is in the premise assessment for your systems such as explaining page for the six.
Okay, secure the policy.
An organizational security policy applies to all systems and sets out what should and should not be allowed.
For example, a military policy might be readers may only examine documents whose classification is the same as or below the readers vetting level.
A security policy sets out the conditions that must be maintained by a security system and so helps identify system security requirements.
Okay.
Security requirements for the MHCPMS.
Patient information shall be downloaded at the start of a clinic session to a secure area on the system client that is used by clinical staff.
All patient information on the system client shall be encrypted.
Patient information shall be uploaded to the database after a clinic session has finished and deleted from the client computer.
A log on a separate computer from the database server must be maintained of all changes made to the system database.
Okay, so you see these are the security requirements.
And you have to make sure that you are following these to have secure system in mental health care patient management system.
Formal specification.
Formal specification is part of a more general collection of techniques that are known as formal methods.
These are all based on mathematical representation and analysis of software.
Formal methods include formal specification, specification analysis and proof, transformational development, program verification.
Use of formal methods.
The principal benefits of formal methods are in reducing the number of faults in systems.
Consequently, their main area of applicability is in critical systems engineering.
There have been several successful projects where formal methods have been used in this area.
In this area, the use of formal methods is most likely to be cost effective because high system failure costs must be avoided.
Specification in the software process.
Specification and design are inextricably intermingled.
Architectural design is essential to structure a specification and the specification process.
Formal specifications are expressed in a mathematical notation with precisely defined vocabulary, syntax and semantics.
Formal specification in a planned based software process.
Increasing contractor involvement from left to right, decreasing client involvement and specification design.
So, user requirements definition in this area we are doing specification.
We are increasing contractor involvement and decreasing client involvement.
As we go to the right and from user requirements, we involve clients of course from system requirements.
We lesser involve users than we go to the architectural design, the formal specification and then high level design.
It is intermingled as we can see.
Benefits of formal specification.
Developing a formal specification requires the system requirements to be analyzed in detail.
This helps to detect problems in consistencies and in completeness in the requirements.
As the specification is expressed in a formal language, it can be automatically analyzed to discover in consistencies and in completeness.
If you use a formal method such as the B method, you can transform the formal specification into a correct program.
Program testing costs may be reduced if the program is formally verified against its specification.
Okay, that is B method. Let's check it out.
The B method is a method of software development based on B, a tool supported formal method based on an abstract machine notation used in the development of computer software.
It was originally developed in the 1980s by Gene Raymond Abriel, one in France and the UK.
B is related to the Z notation, also originated by Abriel and supports development of programming language code from specifications.
B has been used in major safety critical system applications in Europe, such as the automatic Paris Metro lines 14 and one in the Ariane 5 rocket.
It has robust, commercially available tool support for specification, design, proof and code generation.
Let's look for a let's try to find some images.
Of B methods, okay.
No, not this one.
What kind of tool it is? I'm trying to find.
The B method tool, let's find images to that.
Okay, anyway, we have the idea of what it is.
Acceptance of formal methods.
Formal methods have had limited impact on practical software development, problem owners cannot understand a formal specification and so cannot assess if it is an accurate representation of their requirements.
It is easy to assess the costs of developing a formal specification but harder to assess the benefits.
Managers may therefore be unwilling to invest in formal methods, software engineers are unfamiliar with this approach and are therefore reluctant to propose the use of FM.
Formal methods are still hard to scale up to large systems.
Formal specification is not really compatible with agile development methods.
Okay, the key point of the part 2, that's recap.
Reliability requirements can be defined quantitatively.
They include probability of failure on demand, P-O-F-O-D, rate of occurrence of failure, R-O-C-O-F, and availability available.
Security requirements are more difficult to identify than safety requirements because a system attacker can use knowledge of system vulnerabilities to plan a system attack and can learn about vulnerabilities from unsuccessful attacks.
To specify security requirements, you should identify the assets that are to be protected and define how security techniques and technology should be used to protect these assets.
Formal methods of software development rely on a system specification that is expressed as a mathematical model.
The use of formal methods avoids ambiguity in a critical system specification.
All right, I think this is enough for this week, and let's update the final project file as well.
Okay.
I assume that you have already started the project.
You know, you can also use some of your other projects and prepare this software engineering strategies.
That you are expecting from you.
Okay. Okay. Okay. Let's upload our lecture update at final project file.
Oh, by the way, before we do an update, I will not be asked as well.
Yeah, let's update version and the date.
Okay. I think we can actually be fine.
Or maybe let's find it like this.
Okay.
All right. End of lecture, hopefully see you next week.
